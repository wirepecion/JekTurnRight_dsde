{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7042889f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecursiveScriptModule(\n",
       "  original_name=FloodLSTMBinary\n",
       "  (lstm): RecursiveScriptModule(original_name=LSTM)\n",
       "  (fc): RecursiveScriptModule(original_name=Linear)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# load the scripted model onto CPU if CUDA is not available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = torch.jit.load(\"weights/flood_lstm_scripted.pt\", map_location=device)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# python3 src.ds.test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dffcc25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecursiveScriptModule(\n",
       "  original_name=FloodLSTMBinary\n",
       "  (lstm): RecursiveScriptModule(original_name=LSTM)\n",
       "  (fc): RecursiveScriptModule(original_name=Linear)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33f92561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch in /home/sirav/spark_env/lib/python3.10/site-packages (2.9.1)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cpu/torchvision-0.24.1%2Bcpu-cp310-cp310-manylinux_2_28_x86_64.whl (1.9 MB)\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/cpu/torchaudio-2.9.1%2Bcpu-cp310-cp310-manylinux_2_28_x86_64.whl (493 kB)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/sirav/spark_env/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/sirav/spark_env/lib/python3.10/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/sirav/spark_env/lib/python3.10/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/sirav/spark_env/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /home/sirav/spark_env/lib/python3.10/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: filelock in /home/sirav/spark_env/lib/python3.10/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/sirav/spark_env/lib/python3.10/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/sirav/spark_env/lib/python3.10/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/sirav/spark_env/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: jinja2 in /home/sirav/spark_env/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/sirav/spark_env/lib/python3.10/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/sirav/spark_env/lib/python3.10/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/sirav/spark_env/lib/python3.10/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/sirav/spark_env/lib/python3.10/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/sirav/spark_env/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/sirav/spark_env/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/sirav/spark_env/lib/python3.10/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/sirav/spark_env/lib/python3.10/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: triton==3.5.1 in /home/sirav/spark_env/lib/python3.10/site-packages (from torch) (3.5.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/sirav/spark_env/lib/python3.10/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/sirav/spark_env/lib/python3.10/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/sirav/spark_env/lib/python3.10/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: numpy in /home/sirav/spark_env/lib/python3.10/site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/sirav/spark_env/lib/python3.10/site-packages (from torchvision) (12.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/sirav/spark_env/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/sirav/spark_env/lib/python3.10/site-packages (from jinja2->torch) (3.0.3)\n",
      "Installing collected packages: torchvision, torchaudio\n",
      "Successfully installed torchaudio-2.9.1+cpu torchvision-0.24.1+cpu\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823b996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FloodLSTMBinary(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int = 64, num_layers: int = 1, dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)         # (batch, seq_len, hidden_dim)\n",
    "        last_out = out[:, -1, :]      # (batch, hidden_dim)\n",
    "        logit = self.fc(last_out)     # (batch, 1)\n",
    "        return logit.squeeze(-1)      # (batch,)\n",
    "\n",
    "\n",
    "TIME_FEATURES = [\n",
    "    \"number_of_report_flood\",  \n",
    "    \"water\",                   \n",
    "    # \"total_report\",          \n",
    "]\n",
    "\n",
    "STATIC_FEATURES = [\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "]\n",
    "\n",
    "SEQ_LEN = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a6a08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sirav/spark_env/lib/python3.10/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.6.1 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FloodLSTMBinary(\n",
       "  (lstm): LSTM(4, 64, batch_first=True)\n",
       "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from flood_model_def import FloodLSTMBinary, TIME_FEATURES, STATIC_FEATURES, SEQ_LEN\n",
    "\n",
    "# 1) Load scaler\n",
    "with open(\"weights/scaler.pkl\", \"rb\") as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "# 2) Build model and load CPU weights\n",
    "input_dim = len(TIME_FEATURES) + len(STATIC_FEATURES)\n",
    "model = FloodLSTMBinary(input_dim=input_dim, hidden_dim=64, num_layers=1)\n",
    "state = torch.load(\"weights/model.pth\", map_location=\"cpu\")\n",
    "model.load_state_dict(state)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47a11c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flood probability for กระทุ่มราย: 0.3051 on date 2024-01-01\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../data/processed/flood_data_test.csv\")\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "date = df[\"date\"].iloc[0]\n",
    "subdistrict_name = df[\"subdistrict\"].iloc[0]\n",
    "sub = df[df[\"subdistrict\"] == subdistrict_name].sort_values(\"date\")\n",
    "\n",
    "# build last SEQ_LEN days\n",
    "feat_cols = TIME_FEATURES + STATIC_FEATURES\n",
    "seq = sub[feat_cols].values[-SEQ_LEN:]\n",
    "\n",
    "if len(seq) < SEQ_LEN:\n",
    "    pad = np.zeros((SEQ_LEN - len(seq), seq.shape[1]))\n",
    "    seq = np.vstack([pad, seq])\n",
    "\n",
    "df_input = pd.DataFrame(seq[:, :len(TIME_FEATURES)], columns=TIME_FEATURES)\n",
    "seq[:, :len(TIME_FEATURES)] = scaler.transform(df_input)\n",
    "\n",
    "x = torch.tensor(seq, dtype=torch.float32).unsqueeze(0)  # (1, SEQ_LEN, input_dim)\n",
    "\n",
    "try:\n",
    "    model.to(device)\n",
    "except Exception:\n",
    "    # if model is a scripted module or already on correct device this may fail harmlessly\n",
    "    pass\n",
    "x = x.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logit = model(x)            # (1,)\n",
    "    prob = torch.sigmoid(logit).item()\n",
    "\n",
    "print(f\"Flood probability for {subdistrict_name}: {prob:.4f} on date {date.date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b010e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark_env (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
